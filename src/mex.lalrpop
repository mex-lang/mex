use crate::lexer::{Token, LexicalError};
use crate::ast;

grammar<'input>(source: &'input ast::Source, global: &'input ast::RefScope<'input>);

pub Package: ast::RefScope<'input> = {
    <p: PackageRoot> => {
        ast::Scope::add_space(global.clone(), p)
    },
    <p: PackageNessted> => {
        //let r = ast::Scope::new_package(source.get_name());
        ast::Scope::add_space(global.clone(), p);
        global.clone()
    },
    <root: Package> <p: PackageNessted> => {
        ast::Scope::add_space(root.clone(), p);
        root
    },
    //! => ast::Scope::Error(<>).into()
}

pub PackageItems: Vec<ast::RefScope<'input>> = {
    <p: PackageNessted> => vec![p],
    <mut items: PackageItems> <p: PackageNessted> => {
        items.push(p);
        items
    }
}

pub PackageNessted: ast::RefScope<'input> = {
     "package" <name: Name> "{" "}" => ast::Scope::new_package(name, vec![]),
     "package" <name: Name> "{" <items: PackageItems> "}" => ast::Scope::new_package(name, items),
     <m: Model> => m,
     <i: Enum> => i,
     <f: Fragment> => f,
     <s: Scalar> => s,
     ! => ast::Scope::Error(<>).into()
}

pub PackageRoot: ast::RefScope<'input> = {
     "package" <name: Name> ";" => ast::Scope::new_package(name, vec![])
}

pub Model: ast::RefScope<'input> = {
    "model" <name: Name> "{" "}" => ast::Scope::new_model(name, vec![]),
    "model" <name: Name> "{" <items: ModelItems> "}" => ast::Scope::new_model(name, items),
}

pub ModelItems: Vec<ast::ModelItemDefinition<'input>> = {
    <i: ModelNested> => vec![i],
    <mut items: ModelItems> <i: ModelNested> => {
        items.push(i);
        items
    }
}

pub ModelNested: ast::ModelItemDefinition<'input> = {
    <f: ModelField> ","? => f,
    <s: ModelSpred> ","? => s,
}

pub ModelField: ast::ModelItemDefinition<'input> = {
    <f: Name> ":" <t: Name> => {
        ast::ModelItemDefinition::new_item(f, t)
    }
}

pub ModelSpred: ast::ModelItemDefinition<'input> = {
    "..." <t: Name> => {
        ast::ModelItemDefinition::new_spread(t)
    }
}

pub Fragment: ast::RefScope<'input> = {
    "fragment" <name: Name> "{" "}" => ast::Scope::new_fragment(name, vec![]),
    "fragment" <name: Name> "{" <items: ModelItems> "}" => ast::Scope::new_fragment(name, items),
}

pub Enum: ast::RefScope<'input> = {
    "enum" <name: Name> "{" <items: EnunItems> "}" => ast::Scope::new_enum(name, items)
}

pub EnunItems: Vec<ast::EnumItemDefinition<'input>> = {
    <i: EnumNested> => vec![i],
    <mut items: EnunItems> <i: EnumNested> => {
        items.push(i);
        items
    }
}

pub EnumNested: ast::EnumItemDefinition<'input> = {
    <i: EnunItem> ","? => i,
    <i: EnumTuple> ","? => i,
    <i: EnumRecord> ","? => i,
}

pub EnunItem: ast::EnumItemDefinition<'input> = {
    <name: Name> => ast::EnumItemDefinition::new_item(name)
}

pub EnumRecord: ast::EnumItemDefinition<'input> = {
    <name: Name> "(" "{" <t: ItemType> "}" ")" => ast::EnumItemDefinition::new_record(name, t)
}

pub EnumTuple: ast::EnumItemDefinition<'input> = {
    <name: Name> "(" <t: ItemType> ")" => ast::EnumItemDefinition::new_tuple(name, t)
}

pub Scalar: ast::RefScope<'input> = {
    "scalar" <name: Name> ";" => ast::Scope::new_scalar(name)
}

pub Name: &'input str = {
    <name: "id"> => name
}

pub ItemType: ast::ItemType<'input> = {
    <name: "id"> => ast::ItemType::from_name(name)
}

extern {
  type Location = usize;
  type Error = LexicalError;

  enum Token<'input> {
    "package" => Token::KeywordPackage,
    "model" => Token::KeywordModel,
    "enum" => Token::KeywordEnum,
    "fragment" => Token::KeywordFragment,
    "scalar" => Token::KeywordScalar,

    "id" => Token::Identifier(<&'input str>),
    "int" => Token::Integer(<i64>),

    "(" => Token::LParen,
    ")" => Token::RParen,
    "{" => Token::LBracket,
    "}" => Token::RBracket,
    "<" => Token::Lees,
    ">" => Token::Greater,

    "?" => Token::Question,
    "=" => Token::Assign,
    ";" => Token::Semicolon,
    ":" => Token::Colon,
    "," => Token::Comma,
    "..." => Token::Spread,

    "error" => Token::Error(<LexicalError>),
  }
}

// use lalrpop_util::{ErrorRecovery, ParseError};
//    <err: "error"> => {
//        let error = ErrorRecovery {
//            error: ParseError::User {
//                error: LexicalError::InvalidToken,
//            },
//            dropped_tokens: Vec::new(), // or specify the dropped tokens
//        };
//        errors.push(error);
//        Box::new(ast::Scope::Error)
//    },